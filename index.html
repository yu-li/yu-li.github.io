<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yu Li - Home</title>
    <!-- 引入现代图标库 FontAwesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <!-- [分离指南 step 1]:
         在本地开发时，请新建一个名为 style.css 的文件。
         将下方 <style> 标签内的所有内容剪切到 style.css 中。
    -->

    <!-- [分离指南 step 2]:
         取消下面这行代码的注释，让 HTML 链接到您的外部 CSS 文件。
    -->
    <link rel="stylesheet" href="style.css">

</head>

<body>

    <div class="container">
        <!-- 导航栏 -->
        <header>
            <div class="logo"></div>
            <nav>
                <ul>
                    <li><a href="#about" class="active">Home</a></li>
                    <li><a href="#services">Services</a></li>
                    <li><a href="#news">News</a></li>
                    <li><a href="#publications">Publications</a></li>
                    <!-- 你的 recruit.html 文件可以在这里链接 -->
                    <li><a href="recruit.html">Join Us</a></li>
                    <li></li>
                    <li>
                        <button class="theme-toggle" onclick="toggleTheme()" aria-label="Toggle Dark Mode">
                            <i class="fas fa-moon"></i>
                        </button>
                    </li>
                </ul>
            </nav>
        </header>

        <!-- 个人简介 (Profile) -->
        <section id="about" class="profile-section">
            <div class="profile-text">
                <h1>Yu Li (李昱) </h1>
                <h3>Principal Researcher</h3>
                <h3><a href="https://idea.edu.cn/en">International Digital Economy Academy (IDEA)</a></h3>
                <h3>Guangdong-HongKong-Macau Greater Bay Area</h3>
                <h3>Shenzhen, China</h3>
                <p>
                    I am currently a Principal Researcher at IDEA, where I lead two research groups: one focusing on AI-Generated Content and the other exploring
                    AI for Science. I am passionate about building AI systems for content generation and scientific discovery.
                </p>

                <div class="social-links">
                    <a href="mailto:liyu@idea.edu.cn" title="Email"><i class="fas fa-envelope"></i></a>
                    <a href="https://scholar.google.com/citations?user=j9lwU7kAAAAJ&hl=en" title="Google Scholar"><i
                            class="fas fa-graduation-cap"></i></a>
                    <a href="https://github.com/yu-li" title="GitHub"><i class="fab fa-github"></i></a>
                    <a href="#" title="Twitter"><i class="fab fa-twitter"></i></a>
                    <!-- <a href="#" title="LinkedIn"><i class="fab fa-linkedin"></i></a> -->
                    <!-- 小红书按钮 (灰色) -->
                    <a onclick="showModal('xhs')" title="Xiaohongshu" style="cursor: pointer;">
                        <i class="fas fa-book"></i>
                    </a>
                    <!-- 微信按钮 (灰色) -->
                    <a onclick="showModal('wechat')" title="WeChat" style="cursor: pointer;">
                        <i class="fab fa-weixin"></i>
                    </a>
                </div>
            </div>
            <div class="profile-image-container">
                <!-- 引用你上传的图片 -->
                <img src="img/profile.jpg" alt="Yu Li" class="profile-image">
            </div>
        </section>

        <!-- Services Section (恢复并重组的 Services 板块) -->
        <section id="services">
            <h3 class="section-title">Professional Services</h3>
            <div class="services-container">
                <!-- Area Chair / SPC -->
                <div class="service-group">
                    <h4><i class="fas fa-user-tie"></i>(Lead) Area Chair</h4>
                    <ul class="service-list">
                        <li>CVPR 2023-2026, ECCV 2024</li>
                        <li>NeurIPS 2023-2025, ICML 2025-2026, ICLR 2025</li>
                    </ul>
                </div>

                <!-- Journal Reviewer -->
                <div class="service-group">
                    <h4><i class="fas fa-book-open"></i> Program Chair/Organizer</h4>
                    <ul class="service-list">
                        <li>1-4th PBDL Workshop (in conjunction with ICCV'17-21, CVPR'24)</li>
                    </ul>
                </div>

                <!-- Conference Reviewer -->
                <div class="service-group">
                    <h4><i class="fas fa-comments"></i> Guest Editor</h4>
                    <ul class="service-list">
                        <li>IJCV Special Issue on Physics Based Vision meets Deep Learning</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- 新闻 (News) -->
        <section id="news">
            <h3 class="section-title">Recent News</h3>
            <ul class="news-list">
                <!-- 示例新闻，根据你的 img 文件夹里的内容推测 -->
                <li class="news-item">
                    <span class="news-date">2025.11</span>
                    <span>Looking for self-motivated interns! Check <a href="recruit.html">Recruit</a> page.</span>
                </li>
                <li class="news-item">
                    <span class="news-date">2025.11</span>
                    <span>We have anounced <a href="https://ai4s.idea.edu.cn/ai4s/mozi">Mozi</a>: AI-Driven Drug Discovery Engine.</span>
                </li>
                <li class="news-item">
                    <span class="news-date">2025.11</span>
                    <span>We have anounced <a href="https://approximetal.github.io/VoicePlatform/">Luban</a>: AI Audio & Video Editing and Generation Platform.</span>
                </li>
                <li class="news-item">
                    <span class="news-date">2025.09</span>
                    <span>Two papers accepted to <strong>NeurIPS 2025</strong>.</span>
                </li>
                <li class="news-item">
                    <span class="news-date">2025.07</span>
                    <span>Two papers accepted to <strong>ICCV 2025</strong>.</span>
                </li>

            </ul>
        </section>

        <!-- 论文 (Publications) - Updated with Tabs -->
        <section id="publications">
            <h3 class="section-title">Selected Publications</h3>

            <!-- Tab Navigation -->
            <div class="pub-tabs">
                <button class="tab-btn active" onclick="openTab(event, 'cv')">Computer Vision</button>
                <button class="tab-btn" onclick="openTab(event, 'ai4science')">AI for Science</button>
            </div>

            <!-- Group 1: Computer Vision -->
            <div id="cv" class="pub-group active-group">
                <!-- STEM -->
                <!-- <div class="publication-item">
                    <img src="paper/li_stem.gif" alt="STEM" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">A Video is Worth 256 Bases: Spatial-Temporal Expectation-Maximization Inversion for
                            Zero-Shot Video Editing</div>
                        <div class="pub-authors">
                            Maomao Li, <strong>Yu Li</strong>, Tianyu Yang, Yunfei Liu, Dongxu Yue, Zhihui Lin, Dong Xu
                        </div>
                        <div class="pub-venue">CVPR 2024</div>
                        <div class="pub-links">
                            <a href="https://stem-inv.github.io/page/" class="btn-sm"><i class="fas fa-globe"></i> Website</a>
                        </div>
                    </div>
                </div> -->

                <!-- DiffSHEG -->
                <div class="publication-item">
                    <img src="paper/chen_diffsheg.gif" alt="DiffSHEG" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression
                            and Gesture Generation</div>
                        <div class="pub-authors">
                            Junming Chen, Yunfei Liu, Jianan Wang, Ailing Zeng, <strong>Yu Li</strong>, Qifeng Chen
                        </div>
                        <div class="pub-venue">CVPR 2024</div>
                        <div class="pub-links">
                            <a href="https://jeremycjm.github.io/proj/DiffSHEG/" class="btn-sm"><i class="fas fa-globe"></i> Website</a>
                        </div>
                    </div>
                </div>

                <!-- DWPose -->
                <div class="publication-item">
                    <img src="paper/yang_dwpose2.gif" alt="DWPose" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">DWPose: Effective Whole-body Pose Estimation with Two-stages Distillation</div>
                        <div class="pub-authors">
                            Zhendong Yang, Ailing Zeng, Chun Yuan, <strong>Yu Li</strong>
                        </div>
                        <div class="pub-venue">2023</div>
                        <div class="pub-links">
                            <a href="https://github.com/IDEA-Research/DWPose" class="btn-sm"><i class="fab fa-github"></i> Code</a>
                        </div>
                    </div>
                </div>

                <!-- OSX -->
                <div class="publication-item">
                    <img src="paper/lin_cvpr2023.gif" alt="OSX" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">OSX: One-Stage 3D Whole-Body Mesh Recovery with Component Aware Transformer</div>
                        <div class="pub-authors">
                            Jing Lin, Ailing Zeng, Haoqian Wang, Lei Zhang, <strong>Yu Li</strong>
                        </div>
                        <div class="pub-venue">
                            CVPR 2023
                            <span class="tag">Top 1 on AGORA</span>
                        </div>
                        <div class="pub-links">
                            <a href="https://osx-ubody.github.io/" class="btn-sm"><i class="fab fa-github"></i> Project</a>
                        </div>
                    </div>
                </div>

                <!-- CT^2 -->
                <div class="publication-item">
                    <img src="paper/weng_eccv2022.jpg" alt="CT2" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">CT^2: Colorization Transformer via Color Tokens</div>
                        <div class="pub-authors">
                            Shuchen Weng, Jimeng Sun, <strong>Yu Li</strong>, Si Li, Boxin Shi
                        </div>
                        <div class="pub-venue">
                            ECCV 2022
                            <span class="tag">Oral</span>
                        </div>
                        <div class="pub-links">
                            <a href="https://github.com/shuchenweng/CT2" class="btn-sm"><i class="fab fa-github"></i> Code</a>
                            <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136670001.pdf" class="btn-sm"><i
                                    class="far fa-file-pdf"></i> PDF</a>
                        </div>
                    </div>
                </div>

                <!-- Human Matting -->
                <!-- <div class="publication-item">
                    <img src="paper/chen_accv2022.gif" alt="Human Matting" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Robust Human Matting via Semantic Guidance</div>
                        <div class="pub-authors">
                            Xiangguang Chen*, Ye Zhu*, <strong>Yu Li</strong>, Bingtao Fu, Lei Sun, Ying Shan, Shan Liu
                        </div>
                        <div class="pub-venue">ACCV 2022</div>
                        <div class="pub-links">
                            <a href="https://github.com/cxgincsu/SemanticGuidedHumanMatting" class="btn-sm"><i
                                    class="fab fa-github"></i> Code</a>
                            <a href="https://openaccess.thecvf.com/content/ACCV2022/papers/Chen_Robust_Human_Matting_via_Semantic_Guidance_ACCV_2022_paper.pdf"
                                class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                        </div>
                    </div>
                </div> -->

                <!-- Hybrid Warping Fusion -->
                <div class="publication-item">
                    <img src="paper/li_ijcv2022.gif" alt="Hybrid Warping" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Hybrid Warping Fusion for Video Frame Interpolation</div>
                        <div class="pub-authors">
                            <strong>Yu Li*</strong>, Ye Zhu*, Ruoteng Li, Xintao Wang, Yue Luo, Ying Shan
                        </div>
                        <div class="pub-venue">IJCV 2022</div>
                        <div class="pub-links">
                            <a href="https://link.springer.com/article/10.1007/s11263-022-01683-9" class="btn-sm"><i
                                    class="fas fa-link"></i> Link</a>
                        </div>
                    </div>
                </div>

                <!-- TeViT -->
                <div class="publication-item">
                    <img src="paper/yang_cvpr2022.gif" alt="TeViT" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">TeViT: Temporally Efficient Vision Transformer for Video Instance Segmentation</div>
                        <div class="pub-authors">
                            Shusheng Yang, Xinggang Wang, <strong>Yu Li</strong>, Yuxin Fang, Jiemin Fang, Wenyu Liu, Xun Zhao, Ying
                            Shan
                        </div>
                        <div class="pub-venue">
                            CVPR 2022
                            <span class="tag">Oral</span>
                        </div>
                        <div class="pub-links">
                            <a href="https://github.com/hustvl/TeViT" class="btn-sm"><i class="fab fa-github"></i> Code</a>
                            <a href="https://arxiv.org/pdf/2204.08412.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                        </div>
                    </div>
                </div>

                <!-- QueryInst -->
                <div class="publication-item">
                    <img src="paper/fang_iccv2021.gif" alt="QueryInst" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">QueryInst: Instances as Queries</div>
                        <div class="pub-authors">
                            Yuxin Fang*, Shusheng Yang*, Xinggang Wang, <strong>Yu Li</strong>, Chen Fang, Ying Shan, Bin Feng, Wenyu
                            Liu
                        </div>
                        <div class="pub-venue">ICCV 2021</div>
                        <div class="pub-links">
                            <a href="https://github.com/hustvl/QueryInst" class="btn-sm"><i class="fab fa-github"></i> Code</a>
                            <a href="https://arxiv.org/pdf/2105.01928.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                            <a href="https://www.youtube.com/watch?v=3Fqwvn6_oUQ" class="btn-sm"><i class="fab fa-youtube"></i> Demo</a>
                        </div>
                    </div>
                </div>

                <!-- CrossVIS -->
                <!-- <div class="publication-item">
                    <img src="paper/yang_iccv2021.gif" alt="CrossVIS" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">CrossVIS: Crossover Learning for Fast Online Video Instance Segmentation</div>
                        <div class="pub-authors">
                            Shusheng Yang*, Yuxin Fang*, Xinggang Wang, <strong>Yu Li</strong>, Chen Fang, Ying Shan, Bin Feng, Wenyu
                            Liu
                        </div>
                        <div class="pub-venue">ICCV 2021</div>
                        <div class="pub-links">
                            <a href="https://github.com/hustvl/CrossVIS" class="btn-sm"><i class="fab fa-github"></i> Code</a>
                            <a href="https://arxiv.org/pdf/2104.05970.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                            <a href="https://www.youtube.com/watch?v=tPvYYjTgaNs" class="btn-sm"><i class="fab fa-youtube"></i> Demo</a>
                        </div>
                    </div>
                </div> -->

                <!-- GFP-GAN -->
                <div class="publication-item">
                    <img src="paper/wang_cvpr2021.gif" alt="GFP-GAN" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">GFP-GAN: Towards Real-World Blind Face Restoration with Generative Facial Prior</div>
                        <div class="pub-authors">
                            Xintao Wang, <strong>Yu Li</strong>, Honglun Zhang, Ying Shan
                        </div>
                        <div class="pub-venue">CVPR 2021</div>
                        <div class="pub-links">
                            <a href="https://github.com/TencentARC/GFPGAN" class="btn-sm"><i class="fab fa-github"></i> Code</a>
                            <a href="https://arxiv.org/pdf/2101.04061.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                            <a href="https://xinntao.github.io/projects/gfpgan" class="btn-sm"><i class="fas fa-globe"></i> Website</a>
                        </div>
                    </div>
                </div>

                <!-- Low Light Video -->
                <div class="publication-item">
                    <img src="paper/zhang_cvpr2021.gif" alt="Low Light Video" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Learning Temporal Consistency for Low Light Video Enhancement from Single Images</div>
                        <div class="pub-authors">
                            Fan Zhang, <strong>Yu Li</strong>, Shaodi You, Ying Fu
                        </div>
                        <div class="pub-venue">CVPR 2021</div>
                        <div class="pub-links">
                            <a href="https://github.com/zkawfanx/StableLLVE" class="btn-sm"><i class="fab fa-github"></i> Code</a>
                            <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Learning_Temporal_Consistency_for_Low_Light_Video_Enhancement_From_Single_CVPR_2021_paper.pdf"
                                class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                        </div>
                    </div>
                </div>

                <!-- Dual Semantic Fusion -->
                <!-- <div class="publication-item">
                    <img src="paper/lin_mm2020_vod.gif" alt="Dual Semantic" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Dual Semantic Fusion Network for Video Object Detection</div>
                        <div class="pub-authors">
                            Lijian Lin, Haosheng Chen, Honglun Zhang, Jun Liang, <strong>Yu Li</strong>, Ying Shan, Hanzi Wang
                        </div>
                        <div class="pub-venue">ACM MM 2020</div>
                        <div class="pub-links">
                            <a href="https://dl.acm.org/doi/pdf/10.1145/3394171.3413583" class="btn-sm"><i class="fas fa-link"></i>
                                Link</a>
                        </div>
                    </div>
                </div> -->

                <!-- Fast VOS -->
                <div class="publication-item">
                    <img src="paper/li_eccv2020.gif" alt="Fast VOS" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Fast Video Object Segmentation using the Global Context Module</div>
                        <div class="pub-authors">
                            <strong>Yu Li</strong>*, Zhuoran Shen*, Ying Shan
                        </div>
                        <div class="pub-venue">ECCV 2020</div>
                        <div class="pub-links">
                            <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123550732.pdf" class="btn-sm"><i
                                    class="far fa-file-pdf"></i> PDF</a>
                        </div>
                    </div>
                </div>

                <!-- Intrinsic Image -->
                <div class="publication-item">
                    <img src="paper/liu_cvpr2020.jpg" alt="Intrinsic Image" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Unsupervised Learning for Intrinsic Image Decomposition from a Single Image</div>
                        <div class="pub-authors">
                            Yunfei Liu, <strong>Yu Li</strong>, Shaodi You, Feng Lu
                        </div>
                        <div class="pub-venue">CVPR 2020</div>
                        <div class="pub-links">
                            <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Unsupervised_Learning_for_Intrinsic_Image_Decomposition_From_a_Single_Image_CVPR_2020_paper.pdf"
                                class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                        </div>
                    </div>
                </div>

                <!-- Depth Estimation -->
                <!-- <div class="publication-item">
                    <img src="paper/hao_3dv2018.jpg" alt="Depth Estimation" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Detail Preserving Depth Estimation from a Single Image Using Attention Guided Networks
                        </div>
                        <div class="pub-authors">
                            Zhixiang Hao, <strong>Yu Li</strong>, Shaodi You, Feng Lu
                        </div>
                        <div class="pub-venue">3DV 2018</div>
                        <div class="pub-links">
                            <a href="https://arxiv.org/pdf/1809.00646.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                        </div>
                    </div>
                </div> -->

                <!-- Image Filtering -->
                <div class="publication-item">
                    <img src="paper/guo_pami2018.jpg" alt="Image Filtering" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Mutually Guided Image Filtering</div>
                        <div class="pub-authors">
                            Xiaojie Guo, <strong>Yu Li</strong>, Jiayi Ma, Haibin Ling
                        </div>
                        <div class="pub-venue">ACM MM 2017 & T-PAMI 2018</div>
                        <div class="pub-links">
                            <a href="https://ieeexplore.ieee.org/abstract/document/8550683" class="btn-sm"><i class="fas fa-link"></i>
                                Link</a>
                        </div>
                    </div>
                </div>

                <!-- LIME -->
                <div class="publication-item">
                    <img src="paper/guo_tip2016.jpg" alt="LIME" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">LIME: Low-light Image Enhancement via Illumination Map Estimation</div>
                        <div class="pub-authors">
                            Xiaojie Guo, <strong>Yu Li</strong>, Haibin Ling
                        </div>
                        <div class="pub-venue">T-IP 2016</div>
                        <div class="pub-links">
                            <a href="https://ieeexplore.ieee.org/abstract/document/7782813" class="btn-sm"><i class="fas fa-link"></i>
                                Link</a>
                        </div>
                    </div>
                </div>

                <!-- PatchMatch Filter -->
                <div class="publication-item">
                    <img src="paper/lu_tpami2016.jpg" alt="PatchMatch Filter" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">PatchMatch Filter: Edge-Aware Filtering Meets Randomized Search for Correspondence Field
                            Estimation</div>
                        <div class="pub-authors">
                            Jiangbo Lu, <strong>Yu Li</strong>, Hongsheng Yang, Dongbo Min, Weiyong Eng, Minh N. Do
                        </div>
                        <div class="pub-venue">T-PAMI 2016</div>
                        <div class="pub-links">
                            <a href="https://ieeexplore.ieee.org/abstract/document/7588057" class="btn-sm"><i class="fas fa-link"></i>
                                Link</a>
                        </div>
                    </div>
                </div>

                <!-- Fast Guided Interpolation -->
                <div class="publication-item">
                    <img src="paper/li_eccv16_fgi.jpg" alt="Fast Guided Interpolation" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Fast Guided Global Interpolation for Depth and Motion</div>
                        <div class="pub-authors">
                            <strong>Yu Li</strong>, Dongbo Min, Minh N. Do, Jiangbo Lu
                        </div>
                        <div class="pub-venue">
                            ECCV 2016
                            <span class="tag">Spotlight</span>
                        </div>
                        <div class="pub-links">
                            <a href="http://publish.illinois.edu/visual-modeling-and-analytics/fast-guided-global-interpolation/"
                                class="btn-sm"><i class="fas fa-globe"></i> Project</a>
                        </div>
                    </div>
                </div>

                <!-- Rain Removal -->
                <!-- <div class="publication-item">
                    <img src="paper/li_cvpr16_rain.jpg" alt="Rain Removal" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Rain Streak Removal Using Layer Priors</div>
                        <div class="pub-authors">
                            <strong>Yu Li</strong>, Robby. T. Tan, Xiaojie Guo, Jiangbo Lu, Michael S. Brown
                        </div>
                        <div class="pub-venue">CVPR 2016</div>
                        <div class="pub-links">
                            <a href="paper/li_cvpr16_rain.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                            <a href="https://github.com/yu-li/LPDerain" class="btn-sm"><i class="fab fa-github"></i> Code</a>
                        </div>
                    </div>
                </div> -->

                <!-- SPM-BP -->
                <div class="publication-item">
                    <img src="paper/li_iccv15_mrf.gif" alt="SPM-BP" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">SPM-BP: Sped-up PatchMatch Belief Propagation for Continuous MRFs</div>
                        <div class="pub-authors">
                            <strong>Yu Li</strong>, Dongbo Min, Michael S. Brown, Minh N. Do, Jiangbo Lu
                        </div>
                        <div class="pub-venue">
                            ICCV 2015
                            <span class="tag">Oral</span>
                        </div>
                        <div class="pub-links">
                            <a href="https://publish.illinois.edu/visual-modeling-and-analytics/efficient-inference-for-continuous-mrfs/"
                                class="btn-sm"><i class="fas fa-globe"></i> Project</a>
                        </div>
                    </div>
                </div>

                <!-- Contrast Enhancement -->
                <!-- <div class="publication-item">
                    <img src="paper/li_eccv14_jpeg.gif" alt="Contrast Enhancement" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">A Contrast Enhancement Framework with JPEG Artifacts Suppression</div>
                        <div class="pub-authors">
                            <strong>Yu Li</strong>, Fangfang Guo, Robby T. Tan, Michael S. Brown
                        </div>
                        <div class="pub-venue">ECCV 2014</div>
                        <div class="pub-links">
                            <a href="paper/li_eccv14_jpeg.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                            <a href="paper/li_eccv14_jpeg.zip" class="btn-sm"><i class="fas fa-code"></i> Code</a>
                        </div>
                    </div>
                </div> -->

                <!-- Layer Separation -->
                <div class="publication-item">
                    <img src="paper/li_cvpr14_layer.gif" alt="Layer Separation" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Single Image Layer Separation using Relative Smoothness</div>
                        <div class="pub-authors">
                            <strong>Yu Li</strong>, Michael S. Brown
                        </div>
                        <div class="pub-venue">
                            CVPR 2014
                            <span class="tag">Oral</span>
                        </div>
                        <div class="pub-links">
                            <a href="paper/li_cvpr14_layer.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                            <a href="paper/li_cvpr14_layer.zip" class="btn-sm"><i class="fas fa-code"></i> Code</a>
                        </div>
                    </div>
                </div>

                <!-- Reflection Removal -->
                <!-- <div class="publication-item">
                    <img src="paper/li_iccv13_reflection.gif" alt="Reflection Removal" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Exploiting Reflection Change for Automatic Reflection Removal</div>
                        <div class="pub-authors">
                            <strong>Yu Li</strong>, Michael S. Brown
                        </div>
                        <div class="pub-venue">ICCV 2013</div>
                        <div class="pub-links">
                            <a href="paper/li_iccv13_reflection.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                            <a href="paper/li_iccv13_reflection.zip" class="btn-sm"><i class="fas fa-file-zipper"></i> Code & Data</a>
                        </div>
                    </div>
                </div> -->

                <!-- Image Stitching -->
                <!-- <div class="publication-item">
                    <img src="paper/eg13_stitching.jpg" alt="Image Stitching" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Seam-Driven Image Stitching</div>
                        <div class="pub-authors">
                            Junhong Gao, <strong>Yu Li</strong>, Tat-Jun Chin, Michael S. Brown
                        </div>
                        <div class="pub-venue">Eurographics (EG) 2013</div>
                        <div class="pub-links">
                            <a href="paper/eg13_stitching.pdf" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                        </div>
                    </div>
                </div> -->
            </div>

            <!-- Group 2: AI for Science -->
            <div id="ai4science" class="pub-group">
                <!-- 示例 AI4Science 论文 (请替换为您真实的成果) -->
                <!-- Patterns 2025 -->
                <div class="publication-item">
                    <!-- 使用 idea.jpg 作为占位图，您可以稍后替换为论文配图 -->
                    <img src="paper/feng_ligunity.jpg" alt="Patterns 2025" class="pub-thumb">
                    <div class="pub-content">
                        <div class="pub-title">Hierarchical affinity landscape navigation through learning a shared pocket-ligand space
                        </div>
                        <div class="pub-authors">
                            Bin Feng, Zijing Liu, Hao Li, Mingjun Yang, Junjie Zou, He Cao, <strong>Yu Li</strong>, Lei Zhang, Sheng
                            Wang
                        </div>
                        <div class="pub-venue">
                            (Cell) Patterns, 2025
                            <span class="tag">Cover Article</span>
                        </div>
                        <div class="pub-links">
                            <!-- 链接暂时留空，如有 URL 可填入 href -->
                            <a href="#" class="btn-sm"><i class="far fa-file-pdf"></i> PDF</a>
                        </div>
                    </div>
                </div>

                <div style="text-align: center; color: var(--date-color); padding: 2rem;">
                    More exciting AI4Science research coming soon...
                </div>
            </div>

        </section>

        <!-- 脚注 -->
        <footer>
            <p>&copy; 2025 Yu Li. All rights reserved. </p>
        </footer>
    </div>

    <!-- Common Modal Structure -->
    <div id="socialModal" class="modal" onclick="if(event.target === this) closeModal()">
        <div class="modal-content">
            <span class="close-modal" onclick="closeModal()">&times;</span>

            <h3 id="modalTitle" style="color: var(--heading-color); margin-bottom: 1rem; font-size: 1.2rem;">
                <!-- Icon and Title will be injected here -->
            </h3>

            <!--
                     请准备两张二维码图片:
                     1. img/xhs_qr.jpg (小红书)
                     2. img/wechat_qr.jpg (微信)
                -->
            <div id="qrContainer" class="qr-placeholder">
                <!-- Image or Placeholder will be injected here -->
            </div>

            <p id="modalDesc" style="margin-top: 1rem; color: var(--text-color); font-size: 0.9rem;">
                <!-- Description text will be injected here -->
            </p>
        </div>
    </div>

    <script>
        // --- 暗色模式切换逻辑 ---
        function toggleTheme() {
            const body = document.body;
            const icon = document.querySelector('.theme-toggle i');

            if (body.getAttribute('data-theme') === 'dark') {
                body.removeAttribute('data-theme');
                icon.classList.remove('fa-sun');
                icon.classList.add('fa-moon');
                localStorage.setItem('theme', 'light');
            } else {
                body.setAttribute('data-theme', 'dark');
                icon.classList.remove('fa-moon');
                icon.classList.add('fa-sun');
                localStorage.setItem('theme', 'dark');
            }
        }

        // 初始化：检查用户之前的偏好
        const savedTheme = localStorage.getItem('theme');
        const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
            document.body.setAttribute('data-theme', 'dark');
            document.querySelector('.theme-toggle i').classList.replace('fa-moon', 'fa-sun');
        }

        // --- Tab 切换逻辑 ---
        function openTab(evt, groupName) {
            // 1. 隐藏所有内容组
            const tabContent = document.getElementsByClassName("pub-group");
            for (let i = 0; i < tabContent.length; i++) {
                tabContent[i].classList.remove("active-group");
            }

            // 2. 移除所有 Tab 按钮的激活状态
            const tabLinks = document.getElementsByClassName("tab-btn");
            for (let i = 0; i < tabLinks.length; i++) {
                tabLinks[i].classList.remove("active");
            }

            // 3. 显示当前内容组，并激活被点击的按钮
            document.getElementById(groupName).classList.add("active-group");
            evt.currentTarget.classList.add("active");
        }

        // --- Modal (弹窗) 逻辑 [UPDATED] ---
        function showModal(type) {
            const modal = document.getElementById('socialModal');
            const titleEl = document.getElementById('modalTitle');
            const qrContainer = document.getElementById('qrContainer');
            const descEl = document.getElementById('modalDesc');

            let iconClass, iconColor, titleText, imgPath, descText;

            if (type === 'xhs') {
                iconClass = 'fas fa-book';
                iconColor = '#ff2442';
                titleText = ' XiaoHongShu';
                imgPath = 'img/xhs_qr.jpg';
                descText = 'Scan to follow me on XiaoHongShu.';
            } else if (type === 'wechat') {
                iconClass = 'fab fa-weixin';
                iconColor = '#07c160';
                titleText = ' WeChat';
                imgPath = 'img/wechat_qr.jpg';
                descText = 'Scan to add me on WeChat.';
            }

            // 设置标题
            titleEl.innerHTML = `<i class="${iconClass}" style="color: ${iconColor}; margin-right: 8px;"></i>${titleText}`;

            // 设置二维码 (检测图片是否存在较难，这里默认尝试加载图片，失败则显示占位符)
            // 为了演示，这里使用 innerHTML 插入 img 标签
            // 请确保你有 img/xhs_qr.jpg 和 img/wechat_qr.jpg
            qrContainer.innerHTML = `<img src="${imgPath}" alt="${titleText} QR Code" class="qr-image" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
                                        <div class="qr-placeholder" style="display:none; width:200px; height:200px; margin:0 auto;">
                                            [Please upload<br>${imgPath}]
                                        </div>`;

            // 设置描述
            descEl.textContent = descText;

            modal.style.display = "block";
        }

        function closeModal() {
            document.getElementById('socialModal').style.display = "none";
        }

    </script>
</body>

</html>
